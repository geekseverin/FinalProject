"""
Module de pr√©processing des donn√©es
"""

import pandas as pd
import numpy as np
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.impute import SimpleImputer
import joblib
from pathlib import Path
import sys
sys.path.append(str(Path(__file__).parent.parent))
from config.config import *

class DataPreprocessor:
    def __init__(self):
        self.scaler = StandardScaler()
        self.label_encoders = {}
        self.imputers = {}
        
    def load_raw_data(self):
        """Charge les donn√©es brutes"""
        try:
            data_path = RAW_DATA_DIR / "student_data.csv"
            return pd.read_csv(data_path)
        except Exception as e:
            print(f"Erreur lors du chargement des donn√©es: {e}")
            return None
    
    def clean_data(self, df):
        """Nettoyage initial des donn√©es"""
        df = df.copy()
        
        # Suppression des doublons
        df = df.drop_duplicates()
        
        # Conversion des types
        df['dropout'] = df['dropout'].map({'Yes': 1, 'No': 0})
        
        # Gestion des valeurs manquantes pour les variables num√©riques
        numeric_cols = df.select_dtypes(include=[np.number]).columns
        for col in numeric_cols:
            if col not in [ID_COLUMN, TARGET_COLUMN]:
                self.imputers[col] = SimpleImputer(strategy='median')
                df[col] = self.imputers[col].fit_transform(df[[col]]).flatten()
        
        # Gestion des valeurs manquantes pour les variables cat√©gorielles
        categorical_cols = df.select_dtypes(include=['object']).columns
        for col in categorical_cols:
            if col != TARGET_COLUMN:
                self.imputers[col] = SimpleImputer(strategy='most_frequent')
                df[col] = self.imputers[col].fit_transform(df[[col]]).flatten()
        
        return df
    
    def encode_categorical_features(self, df):
        """Encodage des variables cat√©gorielles"""
        df = df.copy()
        categorical_cols = ['gender', 'region', 'parent_education']
        
        for col in categorical_cols:
            if col in df.columns:
                self.label_encoders[col] = LabelEncoder()
                df[col] = self.label_encoders[col].fit_transform(df[col])
        
        return df
    
    def create_features(self, df):
        """Cr√©ation de nouvelles variables"""
        df = df.copy()
        
        # Ratio participation/temps
        df['participation_ratio'] = df['forum_posts'] / (df['moodle_hours'] + 1)
        
        # Score d'engagement
        df['engagement_score'] = (
            df['assignments_submitted'] * 0.4 + 
            df['moodle_hours'] * 0.3 + 
            df['forum_posts'] * 0.3
        )
        
        # Cat√©gorie de satisfaction
        df['satisfaction_category'] = pd.cut(df['satisfaction_score'], 
                                           bins=[0, 3, 6, 10], 
                                           labels=['Low', 'Medium', 'High'])
        
        # Encodage de la nouvelle variable cat√©gorielle
        if 'satisfaction_category' in df.columns:
            self.label_encoders['satisfaction_category'] = LabelEncoder()
            df['satisfaction_category'] = self.label_encoders['satisfaction_category'].fit_transform(df['satisfaction_category'])
        
        return df
    
    def scale_features(self, df):
        """Standardisation des variables num√©riques"""
        df = df.copy()
        
        # Colonnes √† standardiser (exclure ID et target)
        cols_to_scale = [col for col in df.columns 
                        if col not in [ID_COLUMN, TARGET_COLUMN] 
                        and df[col].dtype in ['int64', 'float64']]
        
        df[cols_to_scale] = self.scaler.fit_transform(df[cols_to_scale])
        
        return df
    
    def save_preprocessors(self):
        """Sauvegarde des objets de preprocessing"""
        joblib.dump(self.scaler, MODELS_DIR / "scaler.pkl")
        joblib.dump(self.label_encoders, MODELS_DIR / "label_encoders.pkl")
        joblib.dump(self.imputers, MODELS_DIR / "imputers.pkl")
    
    def process_pipeline(self):
        """Pipeline complet de preprocessing"""
        print("üîÑ D√©but du preprocessing des donn√©es...")
        
        # Chargement des donn√©es
        df = self.load_raw_data()
        if df is None:
            return None
        
        print(f"‚úÖ Donn√©es charg√©es: {df.shape}")
        
        # Nettoyage
        df = self.clean_data(df)
        print("‚úÖ Nettoyage termin√©")
        
        # Sauvegarde des donn√©es nettoy√©es
        df.to_csv(PROCESSED_DATA_DIR / "cleaned_data.csv", index=False)
        
        # Encodage
        df = self.encode_categorical_features(df)
        print("‚úÖ Encodage termin√©")
        
        # Cr√©ation de nouvelles variables
        df = self.create_features(df)
        print("‚úÖ Feature engineering termin√©")
        
        # Sauvegarde avec nouvelles variables
        df.to_csv(PROCESSED_DATA_DIR / "features_engineered.csv", index=False)
        
        # Standardisation
        df_scaled = self.scale_features(df)
        print("‚úÖ Standardisation termin√©e")
        
        # Sauvegarde finale
        df_scaled.to_csv(PROCESSED_DATA_DIR / "scaled_data.csv", index=False)
        
        # Sauvegarde des objets de preprocessing
        self.save_preprocessors()
        print("‚úÖ Preprocessing termin√© avec succ√®s!")
        
        return df_scaled

def run_preprocessing():
    """Fonction principale pour ex√©cuter le preprocessing"""
    preprocessor = DataPreprocessor()
    return preprocessor.process_pipeline()

if __name__ == "__main__":
    run_preprocessing()